# ğŸ“„ test DGFiP â€“ Attribution de fiche pratique par similaritÃ© des questions

Ce projet vise Ã  attribuer une **fiche pratique** Ã  une question dâ€™utilisateur, en identifiant une question consensus similaire Ã  lâ€™aide dâ€™un modÃ¨le **Siamese BERT fine-tunÃ©**.

---

## ğŸ“š Objectif

Lâ€™idÃ©e est de dÃ©tecter si deux questions sont similaires (`question_1` et `question_2`).  
Si câ€™est le cas, on transfÃ¨re la **classe (fiche pratique)** de la `question_2` (consensus) Ã  la `question_1`.

---

## ğŸ§  ModÃ¨le utilisÃ© : Entrainement d'un modÃ¨le Siamese basÃ© sur des reprÃ©sentations gelÃ©es de CamemBERT

Le modÃ¨le mis en place repose sur une architecture **Siamese Network** entraÃ®nÃ©e pour dÃ©tecter la similaritÃ© entre deux questions en franÃ§ais.

Le backbone linguistique utilisÃ© est le modÃ¨le prÃ©-entraÃ®nÃ© francophone :
> [`camembert/camembert-base-wikipedia-4gb`](https://huggingface.co/camembert/camembert-base-wikipedia-4gb)

CamemBERT est utilisÃ© **en tant quâ€™extracteur de caractÃ©ristiques figÃ©** (`trainable=False`) : ses poids ne sont pas modifiÃ©s durant lâ€™entraÃ®nement. Le fine-tuning concerne uniquement les **couches supÃ©rieures** du modÃ¨le Siamese.

Cette approche permet dâ€™exploiter la richesse sÃ©mantique de CamemBERT tout en entraÃ®nant un modÃ¨le lÃ©ger et spÃ©cialisÃ© sur la tÃ¢che de similaritÃ©.

### ğŸ”§ Architecture du modÃ¨le :

- **Encodeur partagÃ©** : le modÃ¨le utilise une architecture Siamese oÃ¹ deux questions passent indÃ©pendamment par le **mÃªme encoder CamemBERT** (poids partagÃ©s).
- **Encapsulation BERT** : le modÃ¨le est encapsulÃ© dans une couche personnalisÃ©e (`BertLayer`).
- **Pooling** : sortie moyenne (`GlobalAveragePooling1D`) pour obtenir un vecteur de chaque question.
- **Comparaison** : les vecteurs sont comparÃ©s via la **distance L1** (couche personnalisÃ©e `L1Dist`).
- **Classification** :
  - Dense(512, relu)
  - Dense(1, sigmoid) â†’ prÃ©diction de similaritÃ© (0 ou 1)

### ğŸ”’ BERT figÃ©

Les poids de CamemBERT sont figÃ©s (`trainable=False`) pour accÃ©lÃ©rer lâ€™entraÃ®nement.

### ğŸ“‰ EntraÃ®nement

- **Fonction de perte** : `binary_crossentropy`
- **Optimiseur** : `Adam`, `lr=1e-5`
- **Callbacks** :
  - `EarlyStopping` sur la validation (`patience=5`)
  - `ReduceLROnPlateau` automatique
- **Epochs** : 18
- **Batch size** : 32

### ğŸ“Š Ã‰valuation du modÃ¨le

Le modÃ¨le a Ã©tÃ© Ã©valuÃ© sur un jeu de validation constituÃ© de paires de questions annotÃ©es comme similaires ou non.

### âœ… RÃ©sultats obtenus :

| MÃ©trique              | Score        |
|-----------------------|--------------|
| Accuracy              | 0.80         |


â¡ï¸ Le modÃ¨le atteint **80% de prÃ©cision globale**  sur les donnÃ©es test.  
Il est utilisÃ© pour **transfÃ©rer la fiche pratique** dâ€™une question consensus Ã  une nouvelle question automatiquement.

### ğŸ§ª MÃ©thode dâ€™Ã©valuation

- Les prÃ©dictions sont comparÃ©es Ã  la vÃ©ritÃ© terrain.
- Seules les paires de questions prÃ©dictes comme "similaires" (probabilitÃ© > 0.5) sont utilisÃ©es pour lâ€™attribution de fiche


---

ğŸ¯ **Objectif** : prÃ©dire si deux questions sont similaires (`1`) ou non (`0`), afin de transfÃ©rer la fiche pratique de la question consensus vers la nouvelle question.

--

## ğŸ“ Contenu du dÃ©pÃ´t

| Fichier / Dossier          | Description |
|----------------------------|-------------|
| `notebook_model.ipynb`     | Notebook dâ€™entraÃ®nement du modÃ¨le Siamese BERT |
| `info_particulier_impot.csv`     | DonnÃ©es |
| `questions_fiches_fip.csv`     | DonnÃ©es |
| `data/`                    | jeu de paires de questions annotÃ©es (pour l'entrainement de Siamese BERT) |
| `README.md`                | Fichier de prÃ©sentation |


---
